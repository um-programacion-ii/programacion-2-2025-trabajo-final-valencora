spring:
  application:
    name: proxy
  kafka:
    # Usar IP directamente para evitar problemas de resolución DNS
    bootstrap-servers: ${KAFKA_BOOTSTRAP_SERVERS:192.168.194.250:9092}
    consumer:
      group-id: ${KAFKA_CONSUMER_GROUP_ID:valencoratolo-2025}
      auto-offset-reset: earliest
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      value-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      enable-auto-commit: true
      properties:
        # Configuración para hacer el consumer más resiliente
        # Tiempo máximo para esperar metadata del broker (en ms) - 5 minutos
        max.poll.interval.ms: 300000
        # Tiempo de sesión (en ms) - 30 segundos
        session.timeout.ms: 30000
        # Heartbeat interval (en ms) - 10 segundos
        heartbeat.interval.ms: 10000
        # Retry configuration
        retry.backoff.ms: 1000
        # Connection timeout - 9 minutos
        connections.max.idle.ms: 540000
        # Metadata fetch timeout
        metadata.max.age.ms: 300000
        # Configuración DNS para manejar nombres de brokers
        # 'use_all_dns_ips' intenta resolver todos los IPs si el broker se anuncia con un nombre
        # Nota: Si el broker se anuncia como "kafka" y no se puede resolver, verás warnings
        # pero la aplicación seguirá funcionando ya que Spring Kafka usará el bootstrap server
        client.dns.lookup: use_all_dns_ips
    producer:
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      value-serializer: org.apache.kafka.common.serialization.StringSerializer
      properties:
        # Configuración para hacer el producer más resiliente
        retries: 3
        retry.backoff.ms: 1000
        request.timeout.ms: 30000
        delivery.timeout.ms: 120000
    listener:
      # Configurar el listener para que sea más tolerante a errores
      missing-topics-fatal: false
      # Permitir que el listener continúe aunque el topic no exista
      auto-startup: true
  data:
    redis:
      host: ${REDIS_HOST:192.168.194.250}
      port: ${REDIS_PORT:6379}
      timeout: 2000ms
      lettuce:
        pool:
          max-active: 8
          max-idle: 8
          min-idle: 0

server:
  port: ${SERVER_PORT:8081}

application:
  backend:
    base-url: ${BACKEND_BASE_URL:http://localhost:8080}
    sync-events-path: ${BACKEND_SYNC_EVENTS_PATH:/api/admin/eventos/sincronizar}
    jwt:
      secret: ${BACKEND_JWT_SECRET:NTUyYWZmNTFlMjhhNjJiNWM5MWVlMTBlZmIwZGNhNjQ2NjYwNTYyODNmNjkyMDM1ZDM0ZjczN2E5YmY4NDc0MmJlMjI5M2I1NjFjOTY5ZDQ5NzAwNmM5YTUxOGM3YTg5NWZmN2RmNTVjOWE5YTA3YTg3YTU1M2E2NzI3NTJhNDg=}
      token-validity-in-seconds: 86400
  catedra:
    base-url: ${CATEDRA_BASE_URL:http://192.168.194.250:8080}
    auth-token: ${CATEDRA_AUTH_TOKEN:eyJhbGciOiJIUzUxMiJ9.eyJzdWIiOiJ2YWxlbjIiLCJleHAiOjE3NjkwMTU0MzUsImF1dGgiOiJST0xFX1VTRVIiLCJpYXQiOjE3NjY0MjM0MzV9.E1EOrMQJhztJ7mAKuMfW2nAqCrSjgUrrsY1UmYwLMmWuIJmS_3x_bWFWhZu8d9vdkNG9tqMFr-KlpAJfs-GWUQ}
  kafka:
    topic:
      eventos: ${KAFKA_TOPIC_EVENTOS:eventos-actualizacion}

logging:
  level:
    root: INFO
    com.um.eventosproxy: DEBUG
    org.springframework.kafka: INFO
    org.apache.kafka: WARN
    # Reducir logs de conexión de Kafka - estos warnings son normales si Kafka
    # se anuncia con un nombre de host que no se puede resolver (ej: "kafka")
    # La aplicación seguirá funcionando ya que usa el bootstrap server
    org.apache.kafka.clients.NetworkClient: ERROR
    org.apache.kafka.clients.consumer.internals.ConsumerCoordinator: ERROR